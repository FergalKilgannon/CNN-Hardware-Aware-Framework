{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from naive_mnist import NaiveModel\n",
    "from nni.algorithms.compression.pytorch.quantization import QAT_Quantizer\n",
    "from nni.compression.pytorch.quantization.settings import set_quant_scheme_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# INT8 weight, INT8 activations\n",
    "num_bits = 9\n",
    "# Make sure this matches quantization config from MNIST_CNN_Training\n",
    "configure_list = [{\n",
    "    'quant_types': ['weight', 'input'],\n",
    "    'quant_bits': {'weight': num_bits, 'input': num_bits},\n",
    "    'quant_start_step': 2,\n",
    "    'op_names': ['conv1', 'conv2']\n",
    "}, {\n",
    "    'quant_types': ['output'],\n",
    "    'quant_bits': {'output': num_bits},\n",
    "    'quant_start_step': 2,\n",
    "    'op_names': ['relu1', 'relu2', 'relu3']\n",
    "}, {\n",
    "    'quant_types': ['output', 'weight', 'input'],\n",
    "    'quant_bits': {'output': num_bits, 'weight': num_bits, 'input': num_bits},\n",
    "    'quant_start_step': 2,\n",
    "    'op_names': ['fc1', 'fc2'],\n",
    "}]\n",
    "\n",
    "set_quant_scheme_dtype('weight', 'per_tensor_symmetric', 'int')\n",
    "set_quant_scheme_dtype('output', 'per_tensor_symmetric', 'int')\n",
    "set_quant_scheme_dtype('input', 'per_tensor_symmetric', 'int')\n",
    "\n",
    "# Load MNIST dataset with train/test split sets.\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=trans),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=trans),\n",
    "    batch_size=100, shuffle=True)\n",
    "\n",
    "idim = next(iter(train_loader))[0][0].size()[1]\n",
    "ifmap = next(iter(train_loader))[0][0].size()[0]\n",
    "fc2_nodes = len(torch.unique(train_loader.dataset.targets))\n",
    "\n",
    "# Create a NaiveModel object and apply QAT_Quantizer setup\n",
    "model_path = \"models/mnist_model_9bit.pth\"\n",
    "qmodel = NaiveModel().to(device)\n",
    "dummy_input = torch.randn(1, ifmap, idim, idim).to(device)\n",
    "optimizer = torch.optim.SGD(qmodel.parameters(), lr=0.01, momentum=0.5)\n",
    "# To enable batch normalization folding in the training process, you should\n",
    "# pass dummy_input to the QAT_Quantizer.\n",
    "quantizer = QAT_Quantizer(qmodel, configure_list, optimizer, dummy_input=dummy_input)\n",
    "quantizer.compress()\n",
    "\n",
    "# Load trained model (from MNIST_CNN_Training step).\n",
    "state = torch.load(model_path, map_location=device)\n",
    "qmodel.load_state_dict(state, strict=True)\n",
    "qmodel.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Fake' Quantization function [Jacob et. al]\n",
    "def quantize(real_value, scale, zero_point, qmin, qmax):\n",
    "    transformed_val = zero_point + real_value / scale\n",
    "    clamped_val = torch.clamp(transformed_val, qmin, qmax)\n",
    "    quantized_val = torch.round(clamped_val)\n",
    "    return quantized_val\n",
    "\n",
    "# Scaling function (Jacob et. al)\n",
    "def scale_quant(real_value, num_bits):\n",
    "    qmin = -(2 ** (num_bits - 1) - 1)\n",
    "    qmax = 2 ** (num_bits - 1) - 1\n",
    "    abs_max = torch.abs(real_value).max()\n",
    "    scale = abs_max / (float(qmax - qmin) / 2)\n",
    "    zero_point = 0\n",
    "    quant = quantize(real_value, scale, zero_point, qmin, qmax)\n",
    "    return scale, quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = qmodel.conv1.module\n",
    "num_bits = 9\n",
    "\n",
    "sw_conv, filters_conv = scale_quant(conv.weight.cpu(), num_bits)\n",
    "kernel = filters_conv[0][0]\n",
    "\n",
    "s_in, x = scale_quant(test_loader.dataset.data, num_bits)\n",
    "\n",
    "image = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"templates/TB_template.v\", \"r\") as f_in:\n",
    "    file_data = f_in.readlines()\n",
    "\n",
    "for index, line in enumerate(file_data):\n",
    "    if \"// Start of custom\" in line:\n",
    "        start_point = index + 1\n",
    "count = 0\n",
    "\n",
    "for y in range(image.size()[1]-kernel.size()[1]):\n",
    "    for x in range(image.size()[1]-kernel.size()[1]):\n",
    "        mac_result = 0\n",
    "        for yb in range(kernel.size()[1]):\n",
    "            for xb in range(kernel.size()[1]):\n",
    "                mac_result = mac_result + (image[x+xb][y+yb] * kernel[xb][yb])\n",
    "\n",
    "                if image[x+xb][y+yb].item() < 0:\n",
    "                    image_pre = \"-\"\n",
    "                else:\n",
    "                    image_pre = \"\"\n",
    "                if kernel[xb][yb].item() < 0:\n",
    "                    kernel_pre = \"-\"\n",
    "                else:\n",
    "                    kernel_pre = \"\"\n",
    "\n",
    "                file_data.insert(start_point+count, f\"        #4;\\n        MULT({image_pre}15'd{abs(image[x+xb][y+yb].item()):.0f}, {kernel_pre}15'd{abs(kernel[xb][yb].item()):.0f});\\n\")\n",
    "                count = count + 1\n",
    "        file_data.insert(start_point+count, f\"        #4;\\n        CHECK_ACCUM(15'd{mac_result.item():.0f});\\n\")\n",
    "        count = count + 1\n",
    "\n",
    "with open(\"../../../Hardware/Verilog/mac_TB.v\", 'w') as f_out:\n",
    "    contents = \"\".join(file_data)\n",
    "    f_out.write(contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

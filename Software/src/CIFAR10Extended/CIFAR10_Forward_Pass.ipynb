{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 FORWARD PASS\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from forwardPass import forwardPass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom test model function\n",
    "# Only implements forward pass of neural network - no training done.\n",
    "def test_custom(model, device, test_loader):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    i = 1\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            batch = data.size()[0]\n",
    "\n",
    "            # Custom forward pass function\n",
    "            output = model.forward_pass(data, batch)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            print(f\"ITERATION {i}: Accuracy = {correct/i:.2f}% (cumulative = {correct})\")\n",
    "            i = i+1\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Loss: {test_loss}   Accuracy: {100 * correct / len(test_loader.dataset)}%\\n\")\n",
    "\n",
    "\n",
    "# Test original/default model forward pass.\n",
    "def test(model, device, test_loader):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model.model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Loss: {test_loss}   Accuracy: {100 * correct / len(test_loader.dataset)}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load CIFAR-10 dataset with train/test split sets.\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('data', train=True, download=True, transform=trans),\n",
    "    batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('data', train=False, transform=trans),\n",
    "    batch_size=100, shuffle=True)\n",
    "\n",
    "idim = next(iter(train_loader))[0][0].size()[1]\n",
    "ifmap = next(iter(train_loader))[0][0].size()[0]\n",
    "fc2_nodes = len(set(train_loader.dataset.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for quantized and trained model\n",
    "model_path = \"models/cifar_model_16bit.pth\"\n",
    "\n",
    "# Choose from: 'array', 'ppq_array', 'mismatched_array'\n",
    "array_choice = 'array'\n",
    "\n",
    "# Choose from: 'linear', 'from_table', 'gain_nl', 'noise' (Ignored if using 'mismatched array')\n",
    "mac_choice = 'gain_nl'\n",
    "\n",
    "# MAC_CONSTANTS - What to set it to depends on above choices:\n",
    "#\n",
    "# array_choice = 'mismatched_array' - Set to percentage mismatch (2)\n",
    "# \n",
    "# mac_choice = 'from_table'         - Set to .xlsx file path containing MAC results ('../HardwareSpec/8x8_Mac_result_final.xlsx')\n",
    "# mac_choice = 'gain_nl'            - Set to the gain/non-linearity constants in an array: [a1, a3] ([1.1, 1*10**-5])\n",
    "# mac_choice = 'noise'              - Set to noise sigma value (1)\n",
    "mac_constants = [0.9, -4*10**-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5768980930328369   Accuracy: 79.74%\n",
      "\n",
      "ITERATION 1: Accuracy = 61.00% (cumulative = 61)\n",
      "ITERATION 2: Accuracy = 61.00% (cumulative = 122)\n",
      "ITERATION 3: Accuracy = 62.00% (cumulative = 186)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.50 MiB for an array with shape (320, 32, 32) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m test(non_linear_model, device, test_loader)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate test accuracy of qmodel, with custom forward pass.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtest_custom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_linear_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 13\u001b[0m, in \u001b[0;36mtest_custom\u001b[1;34m(model, device, test_loader)\u001b[0m\n\u001b[0;32m     10\u001b[0m batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Custom forward pass function\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     15\u001b[0m pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ferga\\Documents\\CollegeWork\\Thesis\\Github\\CNN-Hardware-Software-Codesign\\Software\\src\\CIFAR10Extended\\forwardPass.py:34\u001b[0m, in \u001b[0;36mforwardPass.forward_pass\u001b[1;34m(self, data, batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m sin_conv2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconv2\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39minput_scale\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoscale_quant(x, sin_conv2\u001b[38;5;241m.\u001b[39mcpu(), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bits)\n\u001b[1;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin_conv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# ReLU 2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu6(x, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrelu2\u001b[38;5;241m.\u001b[39mmodule)\n",
      "File \u001b[1;32mc:\\Users\\ferga\\Documents\\CollegeWork\\Thesis\\Github\\CNN-Hardware-Software-Codesign\\Software\\src\\CIFAR10Extended\\hardwareClass.py:51\u001b[0m, in \u001b[0;36mhardware.conv2d\u001b[1;34m(self, x, batch, conv, s_in, idim, ifmap, ofmap, knl, padding)\u001b[0m\n\u001b[0;32m     48\u001b[0m bias_conv \u001b[38;5;241m=\u001b[39m conv\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m/\u001b[39m (s_in \u001b[38;5;241m*\u001b[39m sw_conv)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# CONV layer (WSAB dataflow - see convolve2D_wsab function)\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m out_conv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve2D_wsab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mofmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m out_conv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(out_conv)\n\u001b[0;32m     53\u001b[0m out_conv \u001b[38;5;241m=\u001b[39m out_conv\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\ferga\\Documents\\CollegeWork\\Thesis\\Github\\CNN-Hardware-Software-Codesign\\Software\\src\\CIFAR10Extended\\hardwareClass.py:87\u001b[0m, in \u001b[0;36mhardware.convolve2D_wsab\u001b[1;34m(self, image, kernel, bias, padding, strides, batch, ifmap, ofmap, idim, knl, ncol, nrow)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Iterate through image\u001b[39;00m\n\u001b[0;32m     86\u001b[0m image_block \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((block_row \u001b[38;5;241m*\u001b[39m nrow, xOutput, yOutput))\n\u001b[1;32m---> 87\u001b[0m otemp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(block_row, block_col\u001b[38;5;241m*\u001b[39mncol, xOutput, yOutput)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(block_col):\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m br \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(block_row):\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.50 MiB for an array with shape (320, 32, 32) and data type float64"
     ]
    }
   ],
   "source": [
    "# Initialize hardware model\n",
    "non_linear_model = forwardPass(device, idim, ifmap, array_choice, mac_choice, mac_constants, model_path)\n",
    "\n",
    "# Evaluate test accuracy with imported quantized model from mnist_model.pth.\n",
    "test(non_linear_model, device, test_loader)\n",
    "\n",
    "# Evaluate test accuracy of qmodel, with custom forward pass.\n",
    "test_custom(non_linear_model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
